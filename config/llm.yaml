# LLM Service Configuration (OpenAI-compatible API client)

# Network configuration
host: "0.0.0.0"
port: 8001

# OpenAI-compatible API configuration (external service)
openai_api_base: "https://gpt.lazarev.cloud/ollama/v1"
api_key: ""  # Set via MORGAN_LLM_API_KEY environment variable
model: "llama3.2:latest"  # Default model, can be overridden by external API

# Generation parameters
max_tokens: 2048
temperature: 0.7
timeout: 30.0

# Context management
context_window: 4096
max_context_messages: 10

# System prompt
system_prompt: "You are Morgan, a helpful and friendly AI assistant. You assist with answering questions, and perform various tasks."

# Logging
log_level: "INFO"

# Embedding configuration
embedding_model: "qwen3-embedding:latest"

# Feature flags
enable_streaming: true
