# Morgan AI Assistant Documentation

## Overview

Morgan is a self-hosted, local AI assistant designed for home lab environments. It integrates with smart home devices, processes natural language commands, and executes custom tasks - all while keeping your data private and secure on your own hardware.

This documentation provides information about the Morgan AI Assistant architecture, components, installation, configuration, and usage.

## Table of Contents

- [Architecture](#architecture)
- [Core Components](#core-components)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Development](#development)
- [Troubleshooting](#troubleshooting)

## Architecture

Morgan follows a modular microservices architecture with these key components:

```
┌─────────────────────────────────────────────────────────────────┐
│                      Docker Host Environment                    │
│                                                                 │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────────────┐  │
│  │  Web UI /   │    │             │    │ Home Assistant      │  │
│  │  Voice UI   │◄──►│ Morgan Core │◄──►│ Integration Service │  │
│  └─────────────┘    │   Service   │    └─────────────────────┘  │
│         ▲           └─────────────┘              ▲              │
│         │                  ▲                     │              │
│         ▼                  │                     ▼              │
│  ┌─────────────┐           │            ┌─────────────────────┐ │
│  │ User Auth & │           │            │     External API    │ │
│  │   Security  │           │            │     Connections     │ │
│  └─────────────┘           │            └─────────────────────┘ │
│                            │                                    │
│         ┌─────────────────┐│┌────────────────┐ ┌──────────────┐ │
│         │                 │││                │ │              │ │
│         │  Redis Message  │││   PostgreSQL   │ │ File Storage │ │
│         │    Broker       │││    Database    │ │   (Models)   │ │
│         │                 │││                │ │              │ │
│         └─────────────────┘│└────────────────┘ └──────────────┘ │
│                            │                                    │
│  ┌─────────────┐ ┌─────────┴───────┐ ┌─────────────┐            │
│  │             │ │                 │ │             │            │
│  │ LLM Service │ │   TTS Service   │ │ STT Service │            │
│  │    (vLLM)   │ │      (Dia)      │ │  (Whisper)  │            │
│  │             │ │                 │ │             │            │
│  └─────────────┘ └─────────────────┘ └─────────────┘            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Communication Flow

1. **Input Processing**:
   - User provides input via voice (microphone) or text (web UI)
   - Voice input is processed by Whisper STT to convert to text
   
2. **Intent Recognition**:
   - The core service passes the text to the LLM service
   - LLM determines user intent and required actions
   
3. **Service Execution**:
   - For smart home controls, requests route through Home Assistant
   - For information queries, LLM generates appropriate responses
   
4. **Response Generation**:
   - Text responses are generated by the LLM
   - If voice output is requested, TTS converts text to speech
   
5. **User Interaction**:
   - Response is presented to the user via web UI or speakers

## Core Components

### Morgan Core Service

The central orchestration component that manages the entire system:

**Location**: `/core/`

**Responsibilities**:
- Coordinate communication between all services
- Manage conversation state and context
- Route commands to appropriate handlers
- Process user input and format responses

**Key Files**:
- `/core/app.py` - Main application entry point
- `/core/config/core.yaml` - Main configuration
- `/core/config/handlers.yaml` - Command handler definitions

### LLM Service

Provides natural language understanding and response generation:

**Location**: `/llm/`

**Supported Models**:
- Mistral AI's Mixtral (recommended)
- Llama 3
- Custom fine-tuned models

**Key Files**:
- `/llm/config/models.yaml` - Model definitions
- `/llm/config/prompts.yaml` - System prompts for different scenarios

### TTS Service

Converts text responses to natural-sounding speech:

**Location**: `/tts/`

**Features**:
- Ultra-realistic voice generation
- Support for non-verbal expressions (laughter, pauses)
- Voice cloning capabilities

**Key Files**:
- `/tts/config/voices.yaml` - Voice profile settings
- `/tts/voices/` - Custom voice samples

### STT Service

Processes spoken user input to text:

**Location**: `/stt/`

**Features**:
- Accurate transcription in multiple languages
- Robust in noisy environments
- Low-latency processing

**Key Files**:
- `/stt/config/whisper.yaml` - Model and processing settings

### Home Assistant Integration

Connects Morgan to your smart home devices:

**Location**: `/home-assistant/`

**Features**:
- Device discovery and control
- State monitoring and updates
- Automation triggering

**Key Files**:
- `/core/integrations/home_assistant.py` - Integration implementation
- `/core/handlers/home_assistant.py` - Command handler

### Web and Voice UI

User interfaces for interacting with Morgan:

**Location**: `/web-ui/`

**Features**:
- Modern web interface
- Mobile responsive design
- Voice interaction controls
- Conversation history

## Installation

### Prerequisites

1. A Linux-based server (Ubuntu 22.04 LTS recommended)
2. Docker and Docker Compose installed
3. NVIDIA Container Toolkit (for GPU acceleration)
4. Git for repository cloning
5. Home Assistant instance accessible on your network

### Installation Steps

1. Clone the Morgan repository:
   ```bash
   git clone https://github.com/yourusername/morgan-assistant.git /opt/morgan
   cd /opt/morgan
   ```

2. Run the installation script:
   ```bash
   ./scripts/install.sh
   ```

3. Configure your Home Assistant connection in `/opt/morgan/config/core.yaml`:
   ```yaml
   home_assistant:
     url: http://your-home-assistant:8123
     token: your_long_lived_access_token
   ```

4. Start the services:
   ```bash
   docker-compose up -d
   ```

5. Access the web interface at http://[your-server-ip]:8000/ui

## Configuration

### Main Configuration Files

1. **Core Configuration** (`/config/core.yaml`):
   ```yaml
   system:
     name: Morgan
     log_level: info
     data_dir: /app/data
   
   services:
     llm:
       url: http://llm-service:8001
       model: mistral
     tts:
       url: http://tts-service:8002
       default_voice: morgan_default
     stt:
       url: http://stt-service:8003
       model: whisper-large-v3
   
   home_assistant:
     url: http://your-home-assistant:8123
     token: your_long_lived_access_token
   ```

2. **Handler Configuration** (`/config/handlers.yaml`):
   ```yaml
   handlers:
     home_assistant:
       enabled: true
       domains:
         - light
         - switch
         - climate
         - media_player
     
     information:
       enabled: true
       weather_api_key: ""
     
     system:
       enabled: true
       allow_restart: true
       allow_update: true
   ```

3. **Device Configuration** (`/config/devices.yaml`):
   ```yaml
   device_groups:
     living_room:
       - light.living_room
       - media_player.living_room_tv
       - climate.living_room
     
     kitchen:
       - light.kitchen
       - switch.coffee_maker
   
   device_aliases:
     tv: media_player.living_room_tv
     main_lights: light.living_room
     coffee: switch.coffee_maker
   ```

4. **Voice Configuration** (`/config/voices.yaml`):
   ```yaml
   voices:
     morgan_default:
       description: "Default Morgan voice"
       type: "preset"
       preset_id: 12
     
     custom_voice:
       description: "Custom voice profile"
       type: "cloned"
       sample_file: "custom_voice_sample.mp3"
       sample_text: "This is a sample text for voice cloning."
   ```

### Configuring Voice Profiles

To create a custom voice profile:

1. Record a voice sample (30+ seconds of clear speech)
2. Save the recording to `/data/voices/samples/[name].mp3`
3. Add the voice configuration to `/config/voices.yaml`:
   ```yaml
   voices:
     custom_voice:
       description: "Custom voice profile"
       type: "cloned"
       sample_file: "[name].mp3"
       sample_text: "The text content of your recording"
   ```
4. Restart the TTS service:
   ```bash
   docker-compose restart tts-service
   ```

## Usage

### Web Interface

The web interface is accessible at `http://[your-server-ip]:8000/ui` and provides:

- Text chat interface
- Voice input/output capabilities
- Conversation history
- Settings management

### Voice Commands

Morgan supports a wide range of voice commands, including:

#### Smart Home Controls

- "Turn on the living room lights"
- "Set the kitchen lights to 50% brightness"
- "Turn off all lights in the bedroom"
- "Set the thermostat to 72 degrees"
- "Play music on the living room speaker"

#### Information Queries

- "What's the weather like today?"
- "What time is it in Tokyo?"
- "Tell me about quantum computing"
- "How tall is Mount Everest?"

#### System Commands

- "What's your status?"
- "Restart yourself"
- "Change your voice to custom_voice"

### API Access

Morgan provides a RESTful API for integration with other systems:

**Text Input**:
```bash
curl -X POST http://[your-server-ip]:8000/api/text \
  -H "Content-Type: application/json" \
  -d '{"text": "What time is it?", "user_id": "default"}'
```

**Audio Input**:
```bash
curl -X POST http://[your-server-ip]:8000/api/audio \
  -F "audio=@/path/to/audio.wav" \
  -F "user_id=default"
```

## API Reference

### Core Endpoints

#### Text Processing

- **URL**: `/api/text`
- **Method**: `POST`
- **Body**:
  ```json
  {
    "text": "Your message here",
    "user_id": "optional-user-id"
  }
  ```
- **Response**:
  ```json
  {
    "text": "Response text",
    "audio": "base64-encoded-audio-data",
    "actions": []
  }
  ```

#### Audio Processing

- **URL**: `/api/audio`
- **Method**: `POST`
- **Body**: Form data with:
  - `audio`: Audio file (WAV format)
  - `user_id`: Optional user ID
- **Response**:
  ```json
  {
    "text": "Response text",
    "transcribed_text": "Transcribed input",
    "audio": "base64-encoded-audio-data",
    "actions": []
  }
  ```

#### Reset Conversation

- **URL**: `/api/conversation/reset`
- **Method**: `POST`
- **Body**:
  ```json
  {
    "user_id": "optional-user-id"
  }
  ```
- **Response**:
  ```json
  {
    "success": true
  }
  ```

### Status Endpoints

#### Health Check

- **URL**: `/api/health`
- **Method**: `GET`
- **Response**:
  ```json
  {
    "status": "ok",
    "timestamp": 1620000000
  }
  ```

#### System Status

- **URL**: `/api/status`
- **Method**: `GET`
- **Response**:
  ```json
  {
    "version": "0.1.0",
    "uptime": "1d 2h 3m 4s",
    "cpu_percent": 12.3,
    "memory_percent": 45.6,
    "disk_percent": 78.9,
    "service_status": {
      "llm": true,
      "tts": true,
      "stt": true,
      "home_assistant": true
    }
  }
  ```

### Settings Endpoints

#### Get Voices

- **URL**: `/api/voices`
- **Method**: `GET`
- **Response**:
  ```json
  {
    "voices": {
      "morgan_default": {
        "description": "Default Morgan voice",
        "type": "preset"
      },
      "custom_voice": {
        "description": "Custom voice profile",
        "type": "cloned"
      }
    }
  }
  ```

#### Set Voice

- **URL**: `/api/voices`
- **Method**: `POST`
- **Body**:
  ```json
  {
    "user_id": "optional-user-id",
    "voice_id": "morgan_default"
  }
  ```
- **Response**:
  ```json
  {
    "success": true,
    "message": "Voice preference set to morgan_default: Default Morgan voice",
    "voice_id": "morgan_default",
    "description": "Default Morgan voice"
  }
  ```

## Development

### Project Structure

```
/opt/morgan/
├── core/               # Core service
│   ├── api/            # API server
│   ├── config/         # Configuration management
│   ├── conversation/   # Conversation context management
│   ├── handlers/       # Command handlers
│   ├── integrations/   # External integrations
│   ├── models/         # Data models
│   ├── services/       # Service interfaces
│   └── utils/          # Utilities
├── llm/                # LLM service
├── tts/                # TTS service
├── stt/                # STT service
├── web-ui/             # Web interface
├── data/               # Data storage
│   ├── models/         # AI models
│   ├── voices/         # Voice profiles
│   └── conversations/  # Conversation history
├── config/             # Configuration files
└── scripts/            # Utility scripts
```

### Adding Custom Command Handlers

1. Create a new handler file in `/core/handlers/`:
   ```python
   from .base_handler import BaseHandler
   from conversation.context import ConversationContext
   
   class CustomHandler(BaseHandler):
       async def handle(self, params, context):
           # Your handler logic here
           return await self.format_response("Custom response", True)
   ```

2. Register the handler in `/core/handlers/__init__.py`:
   ```python
   from .custom_handler import CustomHandler
   
   def get_handler_registry(core_instance):
       handlers = {
           # ... existing handlers
           "custom.command": CustomHandler(core_instance)
       }
       return handlers
   ```

3. Update the intent classifier in `/core/utils/intent_classifier.py`:
   ```python
   def _load_intent_definitions(self):
       return {
           # ... existing intents
           "custom.command": {
               "parameters": ["param1", "param2"],
               "required": ["param1"]
           }
       }
   ```

### Setting Up a Development Environment

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/morgan-assistant.git
   cd morgan-assistant
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```

3. Install dependencies:
   ```bash
   pip install -r core/requirements.txt
   ```

4. Run the core service in development mode:
   ```bash
   cd core
   python app.py
   ```

## Troubleshooting

### Common Issues

#### LLM Service Not Starting

**Symptoms**: LLM service fails to start or crashes shortly after starting.

**Possible Causes**:
- Insufficient GPU memory
- Model file not found or corrupted
- CUDA driver version mismatch

**Solutions**:
1. Check GPU memory requirements for your chosen model
2. Verify model files exist in `/data/models/llm/`
3. Check CUDA driver compatibility with `nvidia-smi`
4. Try a smaller model or enable model quantization

#### Home Assistant Connection Issues

**Symptoms**: Morgan cannot control smart home devices or reports connection errors.

**Possible Causes**:
- Incorrect Home Assistant URL or token
- Network connectivity issues
- Home Assistant not running

**Solutions**:
1. Verify URL and token in `/config/core.yaml`
2. Check network connectivity between Morgan and Home Assistant
3. Ensure Home Assistant is running and accessible
4. Check logs for specific error messages

#### Voice Recognition Problems

**Symptoms**: Morgan doesn't understand voice commands or transcribes them incorrectly.

**Possible Causes**:
- Poor microphone quality
- Background noise
- Whisper model issues

**Solutions**:
1. Use a better microphone or position it closer
2. Reduce background noise
3. Try a different Whisper model
4. Check logs for specific transcription errors

#### General Troubleshooting Steps

1. Check logs:
   ```bash
   docker-compose logs -f core
   ```

2. Restart services:
   ```bash
   docker-compose restart
   ```

3. Check system resources:
   ```bash
   docker stats
   ```

4. Verify configuration:
   ```bash
   docker-compose config
   ```

### Getting Support

If you encounter issues not covered in this documentation:

1. Check the GitHub repository issues section
2. Join the community Discord server
3. Submit a detailed bug report with logs and system information
