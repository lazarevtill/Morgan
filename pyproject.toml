[project]
name = "morgan"
version = "0.2.0"
description = "Modern AI assistant with Ollama, CUDA 13 optimization, and microservices architecture"
authors = [{ name = "Morgan AI Team" }]
requires-python = ">=3.11"
readme = "README.md"
license = { text = "MIT" }

dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic>=2.5.0",
    "aiohttp>=3.9.0",
    "pyyaml>=6.0.1",
    "python-dotenv>=1.0.0",
    "python-multipart>=0.0.6",
    "structlog>=23.2.0",
    "psutil>=5.9.0",
    "redis>=5.0.0",
    "asyncpg>=0.29.0",
    "websockets>=12.0",
]

[dependency-groups]
# LLM service dependencies (OpenAI-compatible client for Ollama)
llm = [
    "openai>=1.3.0",
]

# TTS service dependencies (CSM Streaming + Coqui TTS fallback with CUDA support)
tts = [
    # Core audio processing
    "soundfile>=0.12.0",
    "librosa>=0.10.0",
    "pydub>=0.25.1",
    "numpy>=1.26.0",
    "scipy>=1.11.0",
    "numba>=0.58.0",
    # PyTorch with CUDA 12.4
    "torch>=2.1.0",
    "torchaudio>=2.1.0",
    "torchvision>=0.16.0",
    # Hugging Face and transformers for CSM
    "huggingface-hub>=0.20.0",
    "transformers>=4.37.0",
    "accelerate>=0.26.0",
    "einops>=0.7.0",
    "flash-attn>=2.5.0",
    # CSM Streaming - Real-time TTS from GitHub
    # Install with: pip install git+https://github.com/davidbrowne17/csm-streaming.git
    # Fallback: Coqui TTS
    "TTS>=0.13.0",
    # System TTS fallback
    "pyttsx3>=2.90",
]

# STT service dependencies (Faster Whisper with CUDA support)
stt = [
    "faster-whisper>=1.0.0",
    "soundfile>=0.12.0",
    "librosa>=0.10.0",
    "pydub>=0.25.1",
    "torch>=2.1.0",
    "torchaudio>=2.1.0",
    "silero-vad>=0.1.0",
]


# Development dependencies
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "httpx>=0.25.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
]

# Configure UV to use Nexus PyPI proxy
[tool.uv]
index-url = "https://nexus.in.lazarev.cloud/repository/pypi-proxy/simple"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
