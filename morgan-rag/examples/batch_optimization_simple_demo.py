#!/usr/bin/env python3
"""
Simple Batch Processing Optimization Demo for Morgan RAG.

Demonstrates the batch processing optimizations without requiring external services.
Shows the core optimization components and their performance improvements.
"""

import time
from typing import List, Dict, Any

from morgan.optimization.batch_processor import get_batch_processor, BatchConfig
from morgan.optimization.connection_pool import get_connection_pool_manager
from morgan.optimization.async_processor import get_async_processor, TaskPriority
from morgan.optimization.emotional_optimizer import get_emotional_optimizer
from morgan.utils.logger import get_logger

logger = get_logger(__name__)


def demo_batch_processor():
    """Demonstrate batch processing optimization."""
    print("\n" + "=" * 60)
    print("BATCH PROCESSOR OPTIMIZATION DEMO")
    print("=" * 60)

    batch_processor = get_batch_processor()

    # Mock embedding function for testing
    def mock_embedding_function(texts: List[str]) -> List[List[float]]:
        """Mock embedding function that simulates processing time."""
        time.sleep(0.01 * len(texts))  # Simulate processing time
        return [[0.1 * i] * 384 for i in range(len(texts))]

    # Test data
    test_texts = [
        f"Test document {i} about batch processing optimization" for i in range(200)
    ]

    print(f"Testing batch processing with {len(test_texts)} texts...")

    # Test batch processing
    start_time = time.time()

    result = batch_processor.process_embeddings_batch(
        texts=test_texts,
        embedding_function=mock_embedding_function,
        show_progress=False,
    )

    processing_time = time.time() - start_time

    print(f"‚úì Batch processing completed:")
    print(f"  - Total items: {result.total_items}")
    print(f"  - Processed: {result.processed_items}")
    print(f"  - Success rate: {result.success_rate:.1f}%")
    print(f"  - Processing time: {processing_time:.2f}s")
    print(f"  - Throughput: {result.throughput:.1f} items/sec")
    print(f"  - Batch sizes used: {result.batch_sizes_used[:5]}...")

    # Get performance metrics
    metrics = batch_processor.get_performance_metrics()
    if metrics:
        print(f"\nüìä Performance Metrics:")
        for op_type, metric in metrics.items():
            print(f"  {op_type}:")
            print(f"    - Operations: {metric.total_operations}")
            print(f"    - Avg throughput: {metric.avg_throughput:.1f} items/sec")
            print(f"    - Peak throughput: {metric.peak_throughput:.1f} items/sec")

    batch_processor.shutdown()
    print("‚úì Batch processor demo completed")


def demo_async_processor():
    """Demonstrate async processing optimization."""
    print("\n" + "=" * 60)
    print("ASYNC PROCESSOR OPTIMIZATION DEMO")
    print("=" * 60)

    async_processor = get_async_processor()

    # Mock processing functions
    def mock_companion_task(user_input: str) -> str:
        """Mock companion interaction task."""
        time.sleep(0.05)  # Simulate processing
        return f"Companion response to: {user_input}"

    def mock_background_task(data: str) -> str:
        """Mock background processing task."""
        time.sleep(0.1)  # Simulate longer processing
        return f"Processed: {data}"

    print("Testing async processing with companion and background tasks...")

    # Test companion tasks (high priority)
    companion_inputs = [
        "I need help with Docker",
        "How do I deploy my application?",
        "I'm having trouble with the configuration",
    ]

    start_time = time.time()

    # Submit companion tasks
    companion_task_ids = []
    for user_input in companion_inputs:
        task_id = async_processor.submit_companion_task(mock_companion_task, user_input)
        companion_task_ids.append(task_id)

    # Submit background tasks
    background_data = [f"background_item_{i}" for i in range(5)]
    background_task_ids = []
    for data in background_data:
        task_id = async_processor.submit_task(
            mock_background_task, data, priority=TaskPriority.LOW
        )
        background_task_ids.append(task_id)

    # Wait for companion tasks (should complete quickly)
    companion_results = async_processor.wait_for_tasks(companion_task_ids, timeout=5.0)
    companion_time = time.time() - start_time

    print(f"‚úì Companion tasks completed in {companion_time:.2f}s:")
    for i, result in enumerate(companion_results):
        if result and result.success:
            print(f"  - Task {i+1}: {result.result[:50]}...")

    # Wait for background tasks
    background_results = async_processor.wait_for_tasks(
        background_task_ids, timeout=10.0
    )
    total_time = time.time() - start_time

    print(f"‚úì All tasks completed in {total_time:.2f}s")

    # Get statistics
    stats = async_processor.get_stats()
    print(f"\nüìä Async Processor Stats:")
    print(f"  - Total tasks: {stats['total_tasks']}")
    print(f"  - Completed: {stats['completed_tasks']}")
    print(f"  - Failed: {stats['failed_tasks']}")
    print(
        f"  - Success rate: {(stats['completed_tasks'] / max(1, stats['total_tasks']) * 100):.1f}%"
    )

    print("‚úì Async processor demo completed")


def demo_emotional_optimizer():
    """Demonstrate emotional processing optimization."""
    print("\n" + "=" * 60)
    print("EMOTIONAL PROCESSING OPTIMIZATION DEMO")
    print("=" * 60)

    emotional_optimizer = get_emotional_optimizer()

    # Test emotional texts
    test_emotions = [
        ("I'm so excited about this new project!", "joy"),
        ("This is really frustrating and annoying", "anger"),
        ("I feel sad about the situation", "sadness"),
        ("I'm worried about the deadline", "fear"),
        ("This is absolutely amazing!", "joy"),
        ("I'm feeling overwhelmed", "sadness"),
    ]

    print(f"Testing emotional processing with {len(test_emotions)} texts...")

    # Test fast emotion detection
    detection_times = []
    detected_emotions = []

    for text, expected_emotion in test_emotions:
        start_time = time.time()

        emotion = emotional_optimizer.detect_emotion_fast(
            text=text, user_id="demo_user", use_cache=False  # Test without cache first
        )

        detection_time = time.time() - start_time
        detection_times.append(detection_time)
        detected_emotions.append(emotion)

        print(f"  Text: '{text[:40]}...'")
        print(
            f"    Detected: {emotion.primary_emotion} (intensity: {emotion.intensity:.2f})"
        )
        print(f"    Time: {detection_time*1000:.1f}ms")

    avg_detection_time = sum(detection_times) / len(detection_times)

    # Test with caching
    print(f"\nTesting with caching enabled...")

    cached_times = []
    for text, _ in test_emotions:
        start_time = time.time()

        emotion = emotional_optimizer.detect_emotion_fast(
            text=text, user_id="demo_user", use_cache=True  # Enable caching
        )

        cached_time = time.time() - start_time
        cached_times.append(cached_time)

    avg_cached_time = sum(cached_times) / len(cached_times)
    cache_speedup = avg_detection_time / avg_cached_time if avg_cached_time > 0 else 0

    print(f"‚úì Emotional processing results:")
    print(f"  - Avg detection time (no cache): {avg_detection_time*1000:.1f}ms")
    print(f"  - Avg detection time (cached): {avg_cached_time*1000:.1f}ms")
    print(f"  - Cache speedup: {cache_speedup:.1f}x")

    # Test batch pattern analysis
    user_emotions = {"demo_user": detected_emotions}

    start_time = time.time()
    patterns = emotional_optimizer.analyze_emotional_patterns_batch(user_emotions)
    pattern_time = time.time() - start_time

    if "demo_user" in patterns:
        pattern = patterns["demo_user"]
        print(f"\n‚úì Emotional pattern analysis ({pattern_time:.3f}s):")
        print(f"  - Dominant emotions: {pattern.dominant_emotions[:3]}")
        print(f"  - Mood trend: {pattern.mood_trend}")
        print(f"  - Emotional volatility: {pattern.emotional_volatility:.2f}")
        print(f"  - Pattern confidence: {pattern.pattern_confidence:.2f}")

    # Get optimization metrics
    metrics = emotional_optimizer.get_optimization_metrics()
    print(f"\nüìä Optimization Metrics:")
    print(f"  - Total detections: {metrics.total_detections}")
    print(f"  - Avg detection time: {metrics.avg_detection_time*1000:.1f}ms")
    print(f"  - Cache hit rate: {metrics.cache_hit_rate:.1f}%")

    # Check real-time target
    if avg_detection_time < 0.1:  # < 100ms
        print(
            f"  üéØ REAL-TIME TARGET ACHIEVED: {avg_detection_time*1000:.1f}ms < 100ms"
        )
    else:
        print(
            f"  ‚ö†Ô∏è  Real-time target not met: {avg_detection_time*1000:.1f}ms >= 100ms"
        )

    print("‚úì Emotional optimizer demo completed")


def demo_connection_pooling():
    """Demonstrate connection pooling optimization."""
    print("\n" + "=" * 60)
    print("CONNECTION POOLING OPTIMIZATION DEMO")
    print("=" * 60)

    pool_manager = get_connection_pool_manager()

    # Mock connection factory
    def mock_connection_factory():
        """Mock connection that simulates database connection."""

        class MockConnection:
            def __init__(self):
                self.connected = True
                time.sleep(0.01)  # Simulate connection time

            def execute(self, query):
                time.sleep(0.005)  # Simulate query time
                return f"Result for: {query}"

            def close(self):
                self.connected = False

        return MockConnection()

    # Create test pool
    from morgan.optimization.connection_pool import PoolConfig

    config = PoolConfig(max_connections=5, min_connections=2)

    pool = pool_manager.create_pool("test_db", mock_connection_factory, config)

    print("Testing connection pooling performance...")

    # Test without pooling (create new connection each time)
    start_time = time.time()

    no_pool_results = []
    for i in range(20):
        conn = mock_connection_factory()
        result = conn.execute(f"SELECT * FROM table_{i}")
        no_pool_results.append(result)
        conn.close()

    no_pool_time = time.time() - start_time

    # Test with connection pooling
    start_time = time.time()

    pool_results = []
    for i in range(20):
        with pool_manager.get_connection("test_db") as conn:
            result = conn.execute(f"SELECT * FROM table_{i}")
            pool_results.append(result)

    pool_time = time.time() - start_time
    pool_speedup = no_pool_time / pool_time if pool_time > 0 else 0

    print(f"‚úì Connection pooling results:")
    print(f"  - Without pooling: {no_pool_time:.3f}s")
    print(f"  - With pooling: {pool_time:.3f}s")
    print(f"  - Speedup: {pool_speedup:.1f}x")

    # Get pool statistics
    stats = pool_manager.get_all_stats()
    print(f"\nüìä Connection Pool Stats:")
    for pool_name, pool_stats in stats.items():
        print(f"  {pool_name}:")
        print(f"    - Total connections: {pool_stats.total_connections}")
        print(f"    - Active: {pool_stats.active_connections}")
        print(f"    - Utilization: {pool_stats.pool_utilization:.1f}%")
        print(f"    - Avg response time: {pool_stats.avg_response_time:.3f}s")

    print("‚úì Connection pooling demo completed")


def main():
    """Run all optimization demos."""
    print("üöÄ MORGAN RAG BATCH PROCESSING OPTIMIZATION DEMO")
    print("=" * 80)
    print("Demonstrating performance improvements through:")
    print("- Batch processing optimization")
    print("- Async processing for real-time interactions")
    print("- Emotional processing optimizations")
    print("- Connection pooling for database operations")
    print("=" * 80)

    try:
        # Run individual demos
        demo_batch_processor()
        demo_async_processor()
        demo_emotional_optimizer()
        demo_connection_pooling()

        print("\n" + "=" * 80)
        print("üéØ BATCH PROCESSING OPTIMIZATION DEMO COMPLETED SUCCESSFULLY!")
        print("=" * 80)
        print("\nKey Achievements:")
        print("‚úì Batch processing with adaptive sizing and parallel execution")
        print("‚úì Async processing for real-time companion interactions")
        print("‚úì Sub-100ms emotional processing for real-time responses")
        print("‚úì Connection pooling for efficient database operations")
        print("‚úì Performance monitoring and optimization metrics")
        print("\nThe optimization system is ready for production use!")

    except Exception as e:
        logger.error(f"Demo failed: {e}")
        print(f"\n‚ùå Demo failed: {e}")
        raise


if __name__ == "__main__":
    main()
